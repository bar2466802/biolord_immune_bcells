{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c70a88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train a `bioLORD` model with `developing human immune across tissue` for `bioLORD` (B-cells)\n",
    "\n",
    "The data was generated by Suo et al.[[1]](https://www.science.org/doi/full/10.1126/science.abo0510) and downloaded from [Lymphoid cells](https://cellgeni.cog.sanger.ac.uk/developmentcellatlas/fetal-immune/PAN.A01.v01.raw_count.20210429.LYMPHOID.embedding.h5ad). <br>\n",
    "The complete dataset contains a cross-tissue single-cell atlas of developing human immune cells across prenatal hematopoietic, lymphoid, and nonlymphoid peripheral organs. This includes over 900,000 cells from which we identified over 100 cell states.\n",
    "\n",
    "[[1] Suo, Chenqu, Emma Dann, Issac Goh, Laura Jardine, Vitalii Kleshchevnikov, Jong-Eun Park, Rachel A. Botting et al. \"Mapping the developing human immune system across organs.\" Science (2022): eabo0510.](https://www.science.org/doi/full/10.1126/science.abo0510)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/cs/usr/bar246802/bar246802/SandBox2023/biolord_immune_bcells/utils\") # add utils\n",
    "sys.path.append(\"/cs/usr/bar246802/bar246802/SandBox2023/biolord\") # set path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-judges",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import biolord\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import umap.plot\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from cluster_analysis import *\n",
    "from formatters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-royalty",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "# Set the device      \n",
    "device = \"gpu\" if torch.backends.cuda.is_built() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-spell",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm(disable=True, total=0)  # initialise internal lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-ivory",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mplscience\n",
    "mplscience.set_style()\n",
    "\n",
    "plt.rcParams['legend.scatterpoints'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-journalist",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-craft",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "SAVE_DIR = \"../output/\"\n",
    "FIG_DIR = \"../figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-flood",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-electric",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata = sc.read(DATA_DIR + \"biolord_immune_bcells_bm.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-summary",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata.obs[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_evaluate_figures(attribute_):\n",
    "    ground_truth_labels = np.array(df[attribute_ + '_key'])\n",
    "    print(\"Number of samples:\", ground_truth_labels.size)\n",
    "    title = \"Attribute: \" + attribute_ \n",
    "    path = FIG_DIR + attribute_ + \"_\"\n",
    "    scores = matrices_figures(transf_embeddings_attributes, ground_truth_labels, df,\n",
    "                        attributes_map_rev, attribute_, title, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_evaluate(model, id_, attributes = ['celltype', 'organ']):\n",
    "    transf_embeddings_attributes, df = get_transf_embeddings_attributes(model)\n",
    "    all_scores = None\n",
    "    for attribute in attributes:\n",
    "        ground_truth_labels = np.array(df[attribute + '_key'])\n",
    "        ground_truth_unique_labels = list(set(ground_truth_labels))\n",
    "        print(f'For attribute {attribute} the # of unique true labels is: {len(ground_truth_unique_labels)}')\n",
    "        path = SAVE_DIR + attribute + \"_\"\n",
    "        n_clusters_range = np.arange(2, 16).astype(int)\n",
    "        scores = get_kmeans_score(transf_embeddings_attributes, ground_truth_labels, n_clusters_range=n_clusters_range, id_=id_, save_path=path)\n",
    "        scores['attribute'] = attribute\n",
    "        if all_scores is not None:\n",
    "            all_scores = pd.concat([all_scores, scores], ignore_index=True)\n",
    "        else:\n",
    "            all_scores = scores\n",
    "    cols = ['attribute', 'score_name', 'score', 'n_clusters']\n",
    "    all_scores = all_scores[cols]\n",
    "    print(all_scores)\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(module_params, trainer_params):   \n",
    "    model = biolord.Biolord(\n",
    "        adata=adata,\n",
    "        n_latent=32,\n",
    "        model_name=\"immune_bcells\",\n",
    "        module_params=module_params,\n",
    "        train_classifiers=False,\n",
    "        split_key=\"split\",\n",
    "    )\n",
    "    \n",
    "    model.train(max_epochs=1000,\n",
    "            use_gpu=True,\n",
    "            batch_size=512,\n",
    "            plan_kwargs=trainer_params,\n",
    "            early_stopping=True,\n",
    "            early_stopping_patience=20,            \n",
    "            check_val_every_n_epoch=10,\n",
    "            enable_checkpointing=False,\n",
    "            num_workers=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_iterations():\n",
    "    arr_n_latent_attribute_categorical = np.arange(20, 31, 5)\n",
    "    arr_reconstruction_penalty = [1e2, 1e3]\n",
    "    arr_unknown_attribute_penalty = [1e-1, 1e1]\n",
    "    arr_unknown_attribute_noise_param = [1e-1, 1e1]\n",
    "\n",
    "    # arr_n_latent_attribute_categorical = [20]\n",
    "    # arr_reconstruction_penalty = [1e3]\n",
    "    # arr_unknown_attribute_penalty = [1e1]\n",
    "    # arr_unknown_attribute_noise_param = [1e1]\n",
    "    \n",
    "    id_ = 56\n",
    "    full_scores = None\n",
    "    for n_latent_attribute_categorical, reconstruction_penalty, unknown_attribute_penalty, unknown_attribute_noise_param in itertools.product(\n",
    "            arr_n_latent_attribute_categorical, arr_reconstruction_penalty,\n",
    "            arr_unknown_attribute_penalty, arr_unknown_attribute_noise_param):\n",
    "        print(f\"loop index is {id_}\")\n",
    "        \n",
    "        biolord.Biolord.setup_anndata(\n",
    "            adata,\n",
    "            categorical_attributes_keys=[\"celltype\", \"organ\", \"age\"],\n",
    "            retrieval_attribute_key=\"sex\",\n",
    "        )\n",
    "        \n",
    "        module_params = {\n",
    "            \"autoencoder_width\": 128,\n",
    "            \"autoencoder_depth\": 2,\n",
    "            \"attribute_nn_width\": 256,\n",
    "            \"attribute_nn_depth\": 2,\n",
    "            \"n_latent_attribute_categorical\": n_latent_attribute_categorical,\n",
    "            \"loss_ae\": \"gauss\",\n",
    "            \"loss_ordered_attribute\": \"gauss\",\n",
    "            \"reconstruction_penalty\": reconstruction_penalty,\n",
    "            \"unknown_attribute_penalty\": unknown_attribute_penalty,\n",
    "            \"unknown_attribute_noise_param\": unknown_attribute_noise_param,\n",
    "            \"attribute_dropout_rate\": 0.1,\n",
    "            \"use_batch_norm\": False,\n",
    "            \"use_layer_norm\": False,\n",
    "            \"seed\": 42,\n",
    "        }\n",
    "\n",
    "        trainer_params = {\n",
    "            \"n_epochs_warmup\": 0,\n",
    "            \"autoencoder_lr\": 1e-4,\n",
    "            \"autoencoder_wd\": 1e-4,\n",
    "            \"attribute_nn_lr\": 1e-2,\n",
    "            \"attribute_nn_wd\": 4e-8,\n",
    "            \"step_size_lr\": 45,\n",
    "            \"cosine_scheduler\": True,\n",
    "            \"scheduler_final_lr\": 1e-5,\n",
    "        }\n",
    "        model = train_model(module_params, trainer_params)\n",
    "        scores = cluster_evaluate(model, id_)\n",
    "        scores['n_latent_attribute_categorical'] = n_latent_attribute_categorical\n",
    "        scores['reconstruction_penalty'] = reconstruction_penalty\n",
    "        scores['unknown_attribute_penalty'] = unknown_attribute_penalty\n",
    "        scores['unknown_attribute_noise_param'] = unknown_attribute_noise_param\n",
    "        scores['id_'] = id_\n",
    "        if full_scores is not None:\n",
    "            full_scores = pd.concat([full_scores, scores], ignore_index=True)\n",
    "        else:\n",
    "            full_scores = scores\n",
    "#         model.save(SAVE_DIR + \"trained_model_\" + str(id_), overwrite=True)\n",
    "\n",
    "        id_ += 1\n",
    "        full_scores.to_csv(SAVE_DIR + \"trained_models_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_iterations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioLordVenv",
   "language": "python",
   "name": "biolordvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}